{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\Experiment\\work')   #   改变当前工作目录到指定路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 20)\n",
      "(2872, 1)\n",
      "(342, 20)\n",
      "(342, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_new=pd.read_csv(r'G:\\\\lhy\\work\\\\train_feature\\\\feature\\\\AAC.csv',header=None)\n",
    "y_new= pd.read_csv(r'G:\\\\lhy\\work\\data/label_train.csv',header=None)\n",
    "\n",
    "X_new1=pd.read_csv(r\"G:\\\\lhy\\work\\\\test_feature\\\\AAC.csv\",header=None)\n",
    "y_new1= pd.read_csv(r'G:\\lhy\\work\\data/label_test.csv',header=None)\n",
    "\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(X_new1.shape)\n",
    "print(y_new1.shape)\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new).ravel()\n",
    "\n",
    "# X_new1 = np.array(X_new1)\n",
    "# y_new1 = np.array(y_new1).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "# X_new = X_new[:, 1:]\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics       # 提供数学统计的函数和工具，如平均数、中位数、众数\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# dataset splitting   将数据集分割成几个较小的独立的部分，包括训练集、验证集、测试集，保证模型在不同的数据子集上都有良好的表现\n",
    "from sklearn.model_selection import train_test_split\n",
    "#   20%的数据作为测试集，80%作为训练集\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {'C': np.logspace(-4,4, num=100), 'max_iter': [5000]}\n",
    "\n",
    "# 初始化逻辑回归模型\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# 初始化网格搜索\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# 在训练数据上进行网格搜索\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "# 输出最优参数组合\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 输出最优参数组合下的平均值和标准差\n",
    "print(\"Best mean balanced accuracy:\", round(grid_search.best_score_, 3))\n",
    "print(\"Standard deviation of balanced accuracy:\", round(grid_search.cv_results_['std_test_score'][grid_search.best_index_], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC : 0.608 ± 0.024\n",
      "Sn  : 0.62 ± 0.013\n",
      "Sp  : 0.577 ± 0.048\n",
      "MCC : 0.177 ± 0.051\n",
      "BACC: 0.599 ± 0.031\n",
      "AUC : 0.616 ± 0.029\n",
      "AP  : 0.542 ± 0.038\n",
      "AUPR: 0.539 ± 0.038\n",
      "F1  : 0.449 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib用于绘图\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, log_loss\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.metrics import (\n",
    "    log_loss, confusion_matrix, roc_auc_score, average_precision_score,\n",
    "    f1_score, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "BACC_collecton = []\n",
    "ACC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "AP=[]\n",
    "AP_collection = []\n",
    "F1_collection = []\n",
    "AUPR_collection = []\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)        \n",
    "all_precision = []      \n",
    "\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0         \n",
    "\n",
    "interp_tpr_collection = []  \n",
    "\n",
    "def categorical_probas_to_classes(p):      \n",
    "    return np.argmax(p, axis=1)       \n",
    "\n",
    "# Initialize model\n",
    "# 138.3209780541621\n",
    "clf = LogisticRegression(C=138.48863713938746 , max_iter=5000)  \n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for train, test in skf.split(X_new, y_new):\n",
    "    # 数据集划分\n",
    "    X_train, X_valid = np.take(X_new, train, axis=0), np.take(X_new, test, axis=0)\n",
    "    y_train, y_valid = np.take(y_new, train, axis=0), np.take(y_new, test, axis=0)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Train loss\n",
    "    y_train_pred_proba = clf.predict_proba(X_train)\n",
    "    train_loss = log_loss(y_train, y_train_pred_proba)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Valid loss\n",
    "    y_valid_pred_proba = clf.predict_proba(X_valid)\n",
    "    valid_loss = log_loss(y_valid, y_valid_pred_proba)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # Prediction\n",
    "    y_valid_pred = categorical_probas_to_classes(y_valid_pred_proba)\n",
    "\n",
    "    y_true_all.extend(y_valid.ravel().astype(int))\n",
    "    y_pred_all.extend(y_valid_pred.astype(int))\n",
    "    y_pred_proba_all.extend(y_valid_pred_proba[:, 1])\n",
    "\n",
    "    # Confusion matrix metrics\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    ACC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collecton.append(0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP))\n",
    "\n",
    "    # ROC-AUC\n",
    "    auc_score = roc_auc_score(y_valid, y_valid_pred_proba[:, 1])\n",
    "    AUC_collection.append(auc_score)\n",
    "\n",
    "    # --- AP, AUPR, F1 ---\n",
    "    ap = average_precision_score(y_valid, y_valid_pred_proba[:, 1])\n",
    "    precision, recall, _ = precision_recall_curve(y_valid, y_valid_pred_proba[:, 1])\n",
    "    aupr = auc(recall, precision)\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "\n",
    "    AP_collection.append(ap)\n",
    "    AUPR_collection.append(aupr)\n",
    "    F1_collection.append(f1)\n",
    "\n",
    "# --- 保存预测结果 ---\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),\n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "\n",
    "# results_df.to_csv(r'E:/Experiment/work/DDE.csv', index=False)\n",
    "\n",
    "# --- 输出评估结果 ---\n",
    "# --- 输出评估结果 ---\n",
    "print(\"ACC :\", round(statistics.mean(ACC_collection), 3), '±', round(statistics.stdev(ACC_collection), 3))\n",
    "print(\"Sn  :\", round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(\"Sp  :\", round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(\"MCC :\", round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(\"BACC:\", round(statistics.mean(BACC_collecton), 3), '±', round(statistics.stdev(BACC_collecton), 3))  # ⭐ 新增\n",
    "print(\"AUC :\", round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n",
    "print(\"AP  :\", round(statistics.mean(AP_collection), 3), '±', round(statistics.stdev(AP_collection), 3))\n",
    "print(\"AUPR:\", round(statistics.mean(AUPR_collection), 3), '±', round(statistics.stdev(AUPR_collection), 3))\n",
    "print(\"F1  :\", round(statistics.mean(F1_collection), 3), '±', round(statistics.stdev(F1_collection), 3))\n",
    "\n",
    "\n",
    "# # 绘制训练集和验证集的损失曲线\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', color='blue', marker='o')\n",
    "# plt.plot(range(1, len(valid_losses) + 1), valid_losses, label='Validation Loss', color='red', marker='x')\n",
    "# plt.xlabel('Fold')\n",
    "# plt.ylabel('Log Loss')\n",
    "# plt.title('Training and Validation Loss Curve (Log Loss)')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC : 0.529 ± 0.0\n",
      "Sn  : 0.52 ± 0.0\n",
      "Sp  : 0.551 ± 0.0\n",
      "MCC : 0.065 ± 0.0\n",
      "BACC: 0.536 ± 0.0\n",
      "AUC : 0.589 ± 0.0\n",
      "AP  : 0.578 ± 0.0\n",
      "AUPR: 0.575 ± 0.0\n",
      "F1  : 0.401 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, f1_score,\n",
    "    average_precision_score, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "Sn_collection = []\n",
    "AAC_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "BACC_collection = []   # ⭐ 新增\n",
    "AUC_collection = []\n",
    "AP_collection = []\n",
    "AUPR_collection = []\n",
    "F1_collection = []\n",
    "all_preds = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "    # 假设 clf、X_new, y_new, X_new1, y_new1 是预定义好的\n",
    "    clf.fit(X_new, y_new)\n",
    "    y_pred_score = clf.predict_proba(X_new1)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)\n",
    "    y_true = y_new1\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn = TP / (TP + FN)\n",
    "    Sp = TN / (TN + FP)\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    BACC = 0.5 * (Sn + Sp)   # ⭐ 新增\n",
    "\n",
    "    Sn_collection.append(Sn)\n",
    "    AAC_collection.append(ACC)\n",
    "    Sp_collection.append(Sp)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collection.append(BACC)   # ⭐ 保存BACC\n",
    "\n",
    "    auc_score = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collection.append(auc_score)\n",
    "\n",
    "    # --- New: AP, AUPR and F1 ---\n",
    "    ap = average_precision_score(y_true, y_pred_score[:, 1])\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_score[:, 1])\n",
    "    aupr = auc(recall, precision)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    AP_collection.append(ap)\n",
    "    AUPR_collection.append(aupr)\n",
    "    F1_collection.append(f1)\n",
    "\n",
    "    # 保存当前折的预测结果\n",
    "    df_fold = pd.DataFrame({\n",
    "        'Fold': [i + 1] * len(y_true),\n",
    "        'True_Label': np.ravel(y_true),\n",
    "        'Predicted_Label': np.ravel(y_pred),\n",
    "        'Predicted_Probability': np.ravel(y_pred_score[:, 1])\n",
    "    })\n",
    "    all_preds.append(df_fold)\n",
    "\n",
    "# 合并所有折结果\n",
    "pred_results_df = pd.concat(all_preds, ignore_index=True)\n",
    "\n",
    "# 保存到 CSV（按需开启）\n",
    "# pred_results_df.to_csv(r'E:\\Experiment\\work\\ESMC_test_LR.csv', index=False)\n",
    "\n",
    "# --- 打印指标统计 ---\n",
    "print(\"ACC :\", round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(\"Sn  :\", round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(\"Sp  :\", round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(\"MCC :\", round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(\"BACC:\", round(statistics.mean(BACC_collection), 3), '±', round(statistics.stdev(BACC_collection), 3))  # ⭐ 新增\n",
    "print(\"AUC :\", round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n",
    "print(\"AP  :\", round(statistics.mean(AP_collection), 3), '±', round(statistics.stdev(AP_collection), 3))\n",
    "print(\"AUPR:\", round(statistics.mean(AUPR_collection), 3), '±', round(statistics.stdev(AUPR_collection), 3))\n",
    "print(\"F1  :\", round(statistics.mean(F1_collection), 3), '±', round(statistics.stdev(F1_collection), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制AUPR曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC : 0.529 ± 0.0\n",
      "Sn  : 0.52 ± 0.0\n",
      "Sp  : 0.551 ± 0.0\n",
      "MCC : 0.081 ± 0.0\n",
      "AUC : 0.589 ± 0.0\n",
      "AP  : 0.578 ± 0.0\n",
      "AUPR: 0.575 ± 0.0\n",
      "F1  : 0.401 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, roc_auc_score, f1_score,\n",
    "    average_precision_score, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "Sn_collection = []\n",
    "AAC_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "AP_collection = []\n",
    "AUPR_collection = []\n",
    "F1_collection = []\n",
    "all_preds = []\n",
    "pr_curves = []   # 保存PR曲线数据\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(2):\n",
    "    # 假设 clf、X_new, y_new, X_new1, y_new1 是预定义好的\n",
    "    clf.fit(X_new, y_new)\n",
    "    y_pred_score = clf.predict_proba(X_new1)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)\n",
    "    y_true = y_new1\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + TN))\n",
    "    MCC_collection.append(MCC)\n",
    "\n",
    "    auc_score = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collection.append(auc_score)\n",
    "\n",
    "    # --- New: AP, AUPR and F1 ---\n",
    "    ap = average_precision_score(y_true, y_pred_score[:, 1])\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_score[:, 1])\n",
    "    aupr = auc(recall, precision)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    AP_collection.append(ap)\n",
    "    AUPR_collection.append(aupr)\n",
    "    F1_collection.append(f1)\n",
    "\n",
    "    # 对齐 thresholds 长度：precision/recall 比 thresholds 多 1\n",
    "    thresholds = np.append(thresholds, np.nan)\n",
    "\n",
    "    # 保存 PR 曲线点 (Fold, Threshold, Precision, Recall)\n",
    "    df_pr = pd.DataFrame({\n",
    "        'Fold': [i + 1] * len(precision),\n",
    "        'Threshold': thresholds,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    })\n",
    "    pr_curves.append(df_pr)\n",
    "\n",
    "    # 保存当前折的预测结果（如果还需要）\n",
    "    df_fold = pd.DataFrame({\n",
    "        'Fold': [i + 1] * len(y_true),\n",
    "        'True_Label': np.ravel(y_true),\n",
    "        'Predicted_Label': np.ravel(y_pred),\n",
    "        'Predicted_Probability': np.ravel(y_pred_score[:, 1])\n",
    "    })\n",
    "    all_preds.append(df_fold)\n",
    "\n",
    "# 合并所有折结果\n",
    "pred_results_df = pd.concat(all_preds, ignore_index=True)\n",
    "pr_curves_df = pd.concat(pr_curves, ignore_index=True)\n",
    "\n",
    "# 保存到 CSV\n",
    "# pred_results_df.to_csv(r'G:\\\\lhy\\work\\AUPR\\\\test_LR_predictions.csv', index=False)\n",
    "pr_curves_df.to_csv(r'G:\\\\lhy\\work\\AUPR\\\\{1}_test_LR_prcurve.csv', index=False)\n",
    "\n",
    "# --- 打印指标统计 ---\n",
    "print(\"ACC :\", round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(\"Sn  :\", round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(\"Sp  :\", round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(\"MCC :\", round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(\"AUC :\", round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n",
    "print(\"AP  :\", round(statistics.mean(AP_collection), 3), '±', round(statistics.stdev(AP_collection), 3))\n",
    "print(\"AUPR:\", round(statistics.mean(AUPR_collection), 3), '±', round(statistics.stdev(AUPR_collection), 3))\n",
    "print(\"F1  :\", round(statistics.mean(F1_collection), 3), '±', round(statistics.stdev(F1_collection), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for i in range(2):\n",
    "    clf.fit(X_new, y_new)\n",
    "    y_pred_score = clf.predict_proba(X_new1)\n",
    "    y_pred = np.argmax(y_pred_score, axis=1)\n",
    "    y_true = y_new1\n",
    "\n",
    "    df_fold = pd.DataFrame({\n",
    "        'Fold': [i + 1] * len(y_true),\n",
    "        'Predicted_Proba': y_pred_score[:, 1].ravel(),\n",
    "        'True_Label': np.ravel(y_true),\n",
    "        'Predicted_Label': y_pred.ravel()    \n",
    "    })\n",
    "    all_preds.append(df_fold)\n",
    "\n",
    "pred_results_df = pd.concat(all_preds, ignore_index=True)\n",
    "# pred_results_df.to_csv(r'G:\\lhy\\work\\AUPR\\test_LR_AUROC.csv', index=False)\n",
    "\n",
    "\n",
    "# 保存到 CSV\n",
    "pred_results_df.to_csv(r'G:\\\\lhy\\work\\AUROC\\\\{1,2,3,4,5}_test_LR_AUROC.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independence test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# result collection list\n",
    "BACC_collecton = []\n",
    "ACC_collection = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = LogisticRegression(C = 17.47528400007683, max_iter=5000)\n",
    "    clf.fit(X_train_whole, y_train_whole)   \n",
    "    y_pred_score = clf.predict_proba(X_new1)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score) \n",
    "    print(y_pred)   \n",
    "    y_true = y_ind_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
