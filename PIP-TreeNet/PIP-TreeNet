
from sklearn.metrics import confusion_matrix
import math
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, ClassifierMixin
from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold

# ———— 修正后的包装器 ————
class WithDecision(BaseEstimator, ClassifierMixin):
    def __init__(self, estimator):
        self.estimator = estimator
    def fit(self, X, y):
        self.estimator.fit(X, y)
        # 关键：暴露底层 estimator 的 classes_
        self.classes_ = self.estimator.classes_
        return self
    def predict(self, X):
        return self.estimator.predict(X)
    def predict_proba(self, X):
        return self.estimator.predict_proba(X)
    def decision_function(self, X):
        proba = self.estimator.predict_proba(X)
        return proba[:,1] - proba[:,0]
def categorical_probas_to_classes(p):
    return np.argmax(p, axis=1)
# X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)

# 1. 定义模型（保持原样）
base_models = [
      ('rf',   WithDecision(RandomForestClassifier(
                 n_estimators=300,
                 max_features='sqrt', 
                 max_depth=15, 
                 class_weight={0:1627,1:1245},
                 random_state=42, 
                 n_jobs=-1))),
    ('et',   WithDecision(ExtraTreesClassifier(
                 n_estimators=200, 
                 max_depth=21, 
                 max_features='sqrt',
                 class_weight={0:1627,1:1245},
                 random_state=42, 
                 n_jobs=-1))),
    ('xgb',  WithDecision(XGBClassifier(
                 n_estimators=403, 
                 max_depth=10, 
                 learning_rate=0.05,
                 subsample=1, colsample_bytree=1,
                 scale_pos_weight=1627/1245,
                 use_label_encoder=False, eval_metric='auc',
                 random_state=42, n_jobs=-1)))
   

]


meta_model = LGBMClassifier(
                 max_depth=10, 
                 learning_rate=0.0548, 
                 num_iterations=255,
                 num_leaves=31, 
                 min_samples_split=9, 
                 min_samples_leaf=1,
                 class_weight={0:1627,1:1245},
                 random_state=42, 
                 n_jobs=-1)



stacking_model = StackingClassifier(estimators=base_models, 
                                    final_estimator=meta_model,
                                    passthrough=True,    # 把原始特征也传给元模型
                                    # stack_method='predict'  # 用概率输出
                                    stack_method='decision_function'
                                    # stack_method='predict_proba'
                                    )

# 2. 训练模型（在整个训练集上）
stacking_model.fit(X_new, y_new)

# 3. 在独立测试集上评估
y_test_pred_proba = stacking_model.predict_proba(X_new1)

y_test_pred = categorical_probas_to_classes(y_test_pred_proba)

# print(y_test_pred)

# 4. 计算测试集指标
TP, FP, FN, TN = confusion_matrix(y_new1, y_test_pred).ravel()

test_accuracy = (TP + TN) / (TP + TN + FP + FN)
test_sensitivity = TP / (TP + FN)
test_specificity = TN / (TN + FP)
test_mcc = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
test_bacc = 0.5 * (test_sensitivity + test_specificity)
test_auc = roc_auc_score(y_new1, y_test_pred_proba[:, 1])

# 5. 输出独立测试集结果
print("Independent Test Set Performance:")
print(f"Accuracy: {test_accuracy:.3f}")
print(f"Sensitivity (Recall): {test_sensitivity:.3f}")
print(f"Specificity: {test_specificity:.3f}")
print(f"MCC: {test_mcc:.3f}")
print(f"AUC-ROC: {test_auc:.3f}")
