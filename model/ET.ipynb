{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\Experiment\\work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 1003)\n",
      "(2872, 1)\n",
      "(342, 1003)\n",
      "(342, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "\n",
    "X_new = pd.read_csv(r'G:/lhy\\work/train_feature/feature\\\\ESMC300+AAC+PAAC.csv', header=None)\n",
    "y_new = pd.read_csv(r'G:\\\\lhy\\work\\data/label_train.csv', header=None)\n",
    "\n",
    "X_new1 = pd.read_csv(r\"G:\\\\lhy\\work\\\\test_feature\\\\ESMC300+AAC+PAAC.csv\", header=None)\n",
    "y_new1 = pd.read_csv(r'G:\\\\lhy\\work\\data/label_test.csv', header=None)\n",
    "\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(X_new1.shape)\n",
    "print(y_new1.shape)\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new).ravel()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_new1 = np.array(X_new1)\n",
    "# y_new1 = np.array(y_new1).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[LightGBM] [Info] Number of positive: 1245, number of negative: 1627\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 251234\n",
      "[LightGBM] [Info] Number of data points in the train set: 2872, number of used features: 1003\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.433496 -> initscore=-0.267602\n",
      "[LightGBM] [Info] Start training from score -0.267602\n",
      "最佳参数: {'max_depth': 35, 'n_estimators': 400}\n",
      "最佳AUC得分: 0.7149671342282768\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 基础参数\n",
    "# base_params = {\n",
    "#     'random_state': 42,\n",
    "#     'n_jobs': -1,\n",
    "#     'class_weight': {0: 1627, 1: 1245}\n",
    "# }\n",
    "\n",
    "# 参数搜索范围\n",
    "param_grid = {\n",
    "    'n_estimators': (100,400,10),\n",
    "    'max_depth': (10,35,1),\n",
    "    # 'num_leaves': [31, 63, 127],\n",
    "    # 'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    # 'min_child_samples': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# 模型和交叉验证配置\n",
    "model = LGBMClassifier()\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 网格搜索\n",
    "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数:\", grid_search.best_params_)\n",
    "print(\"最佳AUC得分:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 交叉验证评估报告（ExtraTreesClassifier） ==========\n",
      "准确率 (AAC): 0.6382\n",
      "灵敏度 (Sn): 0.3952\n",
      "特异度 (Sp): 0.8242\n",
      "马修斯系数 (MCC): 0.2446\n",
      "AUC分数: 0.6684\n",
      "对数损失: 0.6382\n",
      "混淆矩阵:\n",
      "[[1341  286]\n",
      " [ 753  492]]\n",
      "\n",
      "Top 10重要特征:\n",
      "Feature_990: 0.0022\n",
      "Feature_969: 0.0022\n",
      "Feature_203: 0.0021\n",
      "Feature_753: 0.0020\n",
      "Feature_263: 0.0019\n",
      "Feature_681: 0.0019\n",
      "Feature_843: 0.0019\n",
      "Feature_160: 0.0018\n",
      "Feature_981: 0.0018\n",
      "Feature_736: 0.0018\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, log_loss\n",
    "\n",
    "# 拆分数据\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# ExtraTreesClassifier 参数\n",
    "et_params =  {\n",
    "    'n_estimators': 200,      # 增加树的数量\n",
    "    'max_depth': 21,          # 增加深度\n",
    "    # 'min_samples_split': 7,   # 防止过拟合\n",
    "    # 'min_samples_leaf': 1,   # 增加叶子节点的最小样本数\n",
    "    'max_features': 'sqrt',   # 每棵树使用的特征比例\n",
    "    # 'class_weight': 'balanced', # 处理类别不平衡\n",
    "    # 'oob_score': True,  # 关键修复：启用OOB评估\n",
    "    'n_jobs': -1,\n",
    "    'class_weight': {0:1627, 1: 1245},  \n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# 创建包含标准化的管道\n",
    "model = make_pipeline(\n",
    "    # StandardScaler(),  # 如果需要标准化，可以取消注释\n",
    "    ExtraTreesClassifier(**et_params)\n",
    ")\n",
    "\n",
    "# 使用5折交叉验证训练和预测\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(model, X_new, y_new, cv=cv, method='predict')\n",
    "y_proba = cross_val_predict(model, X_new, y_new, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "# 模型拟合（为了提取特征重要性）\n",
    "model.fit(X_new, y_new)\n",
    "\n",
    "# 安全除法函数\n",
    "def safe_divide(a, b):\n",
    "    return a / b if b != 0 else 0\n",
    "\n",
    "# 评估指标\n",
    "cm = confusion_matrix(y_new, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "AAC = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sn = safe_divide(TP, TP + FN)\n",
    "Sp = safe_divide(TN, TN + FP)\n",
    "MCC_num = (TP * TN - FP * FN)\n",
    "MCC_den = math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "MCC = safe_divide(MCC_num, MCC_den)\n",
    "AUC = roc_auc_score(y_new, y_proba)\n",
    "logloss = log_loss(y_new, y_proba)\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\n========== 交叉验证评估报告（ExtraTreesClassifier） ==========\")\n",
    "print(f\"准确率 (AAC): {AAC:.4f}\")\n",
    "print(f\"灵敏度 (Sn): {Sn:.4f}\")\n",
    "print(f\"特异度 (Sp): {Sp:.4f}\")\n",
    "print(f\"马修斯系数 (MCC): {MCC:.4f}\")\n",
    "print(f\"AUC分数: {AUC:.4f}\")\n",
    "print(f\"对数损失: {logloss:.4f}\")\n",
    "print(\"混淆矩阵:\")\n",
    "print(cm)\n",
    "\n",
    "# 特征重要性输出\n",
    "et_model = model.named_steps['extratreesclassifier']\n",
    "importances = et_model.feature_importances_\n",
    "\n",
    "print(\"\\nTop 10重要特征:\")\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "feature_names = X_new.columns if hasattr(X_new, 'columns') else [f'Feature_{i}' for i in range(X_new.shape[1])]\n",
    "for i in sorted_idx[:10]:\n",
    "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632 ± 0.0\n",
      "0.596 ± 0.0\n",
      "0.71 ± 0.0\n",
      "0.284 ± 0.0\n",
      "0.684 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 独立测试\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# result collection list\n",
    "# BACC_collection = []\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "# AP = []\n",
    "# mean_recall = np.linspace(0, 1, 100)\n",
    "# all_precision = []\n",
    "# base_fpr = np.linspace(0, 1, 100)\n",
    "# mean_tpr = 0.0\n",
    "# interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(5):\n",
    "    # dataset splitting\n",
    "    # X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "    \n",
    "    # Create and train Decision Tree classifier\n",
    "    # clf = RandomForestClassifier(max_depth=600, max_features=1, n_estimators=1000, n_jobs=-1)  # need to tune the hyperparameters\n",
    "    # clf.fit(X_train_whole, y_train_whole)\n",
    "    # clf = joblib.load('mode\\RF_ESM300/rf_ESM300_model_fold_5.joblib')\n",
    "    # Predict on independent test set\n",
    "    model.fit(X_new, y_new)\n",
    "    y_pred_score = model.predict_proba(X_new1)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)\n",
    "    y_true = y_new1\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    auc = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "  \n",
    "# Print results\n",
    "print(round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# 初始化指标收集\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "# 保存预测结果\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "# 概率转标签函数\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "# ExtraTrees 分类器\n",
    "clf = ExtraTreesClassifier(max_depth=13, n_estimators=200, random_state=42)\n",
    "\n",
    "# 10折交叉验证\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train, test in skf.split(X_new, y_new):\n",
    "    X_train, X_valid = X_new[train], X_new[test]\n",
    "    y_train, y_valid = y_new[train], y_new[test]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_proba = clf.predict_proba(X_valid)\n",
    "    y_valid_pred = categorical_probas_to_classes(y_pred_proba)\n",
    "\n",
    "    # 保存预测值\n",
    "    y_true_all.extend(y_valid)\n",
    "    y_pred_all.extend(y_valid_pred)\n",
    "    y_pred_proba_all.extend(y_pred_proba[:, 1])  # 正类概率\n",
    "\n",
    "    # 评估指标\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    MCC_collection.append(MCC)\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),\n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "results_df.to_csv(r'E:/Experiment/work/result/10折/ET_DDE.csv', index=False)\n",
    "\n",
    "# 打印平均 ± 标准差\n",
    "print(\"ACC:\", round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(\"Sn :\", round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(\"Sp :\", round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(\"MCC:\", round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(\"AUC:\", round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 独立测试\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# result collection list\n",
    "BACC_collection = []\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "AP = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Create and train Decision Tree classifier\n",
    "    clf = ExtraTreesClassifier(max_depth= 500, n_estimators = 500)  # Using default parameters\n",
    "    clf.fit(X_train_whole, y_train_whole)\n",
    "    \n",
    "    # Predict on independent test set\n",
    "    y_pred_score = clf.predict_proba(X_ind_test)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)\n",
    "    y_true = y_ind_test\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collection.append(0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP))\n",
    "    auc = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "    \n",
    "    \n",
    "# Print results\n",
    "print(round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
