{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\Experiment\\work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 960)\n",
      "(2872, 1)\n",
      "(342, 3380)\n",
      "(342, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "\n",
    "X_new=pd.read_csv(r'train_feature/feature/ESM Cambrian.csv',header=None)\n",
    "y_new= pd.read_csv(r'E:/Experiment\\work\\data/label_train.csv',header=None)\n",
    "\n",
    "X_new1=pd.read_csv(r\"teat_feature\\DDE+DPC+CSKAAP+AAC+ESMC300.csv\",header=None)\n",
    "y_new1= pd.read_csv(r'E:/Experiment\\work\\data/label_test.csv',header=None)\n",
    "\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(X_new1.shape)\n",
    "print(y_new1.shape)\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new).ravel()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_new1 = np.array(X_new1)\n",
    "# y_new1 = np.array(y_new1).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2297, 400)\n",
      "(575, 400)\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier  # 导入XGBoost分类器\n",
    "\n",
    "# 假设 X_new 和 y_new 是你的数据集\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "BACC_collection = []\n",
    "ACC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "# Initialize lists to store predictions and true values for each fold\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "# 初始化XGBoost分类器\n",
    "clf = XGBClassifier(\n",
    "    learning_rate=0.1,  # 学习率\n",
    "    n_estimators=100,  # 树的个数\n",
    "    max_depth=5,  # 树的深度\n",
    "    random_state=1111  # 随机数的种子\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "    X_train, X_valid, y_train, y_valid = X_train_whole[train], X_train_whole[test], y_train_whole[train], y_train_whole[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_valid)\n",
    "    y_valid_pred = categorical_probas_to_classes(y_pred_proba)\n",
    "\n",
    "    y_true_all.extend(y_valid.ravel().astype(int))\n",
    "    y_pred_all.extend(y_valid_pred.astype(int))\n",
    "    y_pred_proba_all.extend(y_pred_proba[:, 1])\n",
    "\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    MCC_collection.append(MCC)\n",
    "    ACC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    BACC_collection.append(0.5 * (TP / (TP + FN)) + 0.5 * (TN / (TN + FP)))\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),\n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(r'E:/Experiment\\work/result/10折/XGB单个特征/XGB_DDE.csv', index=False)\n",
    "\n",
    "# 输出结果\n",
    "print(round(np.mean(ACC_collection), 3), '±', round(np.std(ACC_collection), 3))\n",
    "print(round(np.mean(Sn_collection), 3), '±', round(np.std(Sn_collection), 3))\n",
    "print(round(np.mean(Sp_collection), 3), '±', round(np.std(Sp_collection), 3))\n",
    "print(round(np.mean(MCC_collection), 3), '±', round(np.std(MCC_collection), 3))\n",
    "print(round(np.mean(AUC_collection), 3), '±', round(np.std(AUC_collection), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 1000}\n",
      "Mean Cross-Validation Balanced Accuracy: 0.712\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Define the parameter grid for XGB\n",
    "param_grid = {\n",
    "    'n_estimators': (100,1000,100),  # 缩小范围，选择更合理的值\n",
    "    'learning_rate': (0.01, 0.1,0.05),  # 学习率\n",
    "    'max_depth': (1,20,2) # 树的最大深度\n",
    "    # 'subsample': (0.6, 1.0,0.1),  # 子采样率\n",
    "    # 'colsample_bytree': (0.6, 1.0,0.1)  # 列采样率\n",
    "}\n",
    "\n",
    "# Create an XGB classifier\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# Create stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=skf, scoring='roc_auc')\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "# Get the best parameters and corresponding mean cross-validation score\n",
    "best_params = grid_search.best_params_\n",
    "mean_score = grid_search.best_score_\n",
    "\n",
    "# Get cross-validation scores for all parameter combinations\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the best parameters and mean cross-validation score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Mean Cross-Validation Balanced Accuracy:\", round(mean_score, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.648 ± 0.012\n",
      "Sn : 0.492 ± 0.037\n",
      "Sp : 0.768 ± 0.043\n",
      "MCC: 0.272 ± 0.023\n",
      "AUC: 0.692 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# 初始化指标列表\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "# 保存预测结果\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=503,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.05, \n",
    "    # subsample=1,\n",
    "    # colsample_bytree=1,\n",
    "    scale_pos_weight=1627/1245,  # 计算好的类别不平衡比例\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    # use_label_encoder=False,\n",
    "    # eval_metric='auc'\n",
    ")\n",
    "\n",
    "# 五折交叉验证\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_idx, test_idx in skf.split(X_new, y_new):\n",
    "    X_train, X_valid = X_new[train_idx], X_new[test_idx]\n",
    "    y_train, y_valid = y_new[train_idx], y_new[test_idx]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_proba = clf.predict_proba(X_valid)\n",
    "    y_valid_pred = categorical_probas_to_classes(y_pred_proba)\n",
    "\n",
    "    # 保存预测结果\n",
    "    y_true_all.extend(y_valid)\n",
    "    y_pred_all.extend(y_valid_pred)\n",
    "    y_pred_proba_all.extend(y_pred_proba[:, 1])  # 正类概率\n",
    "\n",
    "    # 计算混淆矩阵及各项指标\n",
    "    TN, FP, FN, TP = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    MCC_collection.append(MCC)\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "# 保存结果为 CSV 文件\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),\n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "results_df.to_csv(r'E:/Experiment\\work/result/10折/XGB单个特征/XGB_ESM Cambrian.csv', index=False)\n",
    "\n",
    "# 输出平均值 ± 标准差\n",
    "print(\"ACC:\", round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(\"Sn :\", round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(\"Sp :\", round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(\"MCC:\", round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(\"AUC:\", round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 交叉验证评估报告（XGBoost） ==========\n",
      "准确率 (AAC): 0.5575\n",
      "灵敏度 (Sn): 0.4651\n",
      "特异度 (Sp): 0.6281\n",
      "马修斯系数 (MCC): 0.0938\n",
      "AUC分数: 0.5606\n",
      "对数损失: 0.7772\n",
      "混淆矩阵:\n",
      "[[1022  605]\n",
      " [ 666  579]]\n",
      "\n",
      "Top 10重要特征:\n",
      "Feature_239: 0.0078\n",
      "Feature_60: 0.0078\n",
      "Feature_179: 0.0073\n",
      "Feature_234: 0.0067\n",
      "Feature_283: 0.0067\n",
      "Feature_161: 0.0066\n",
      "Feature_171: 0.0060\n",
      "Feature_124: 0.0058\n",
      "Feature_235: 0.0057\n",
      "Feature_255: 0.0056\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import joblib\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, log_loss\n",
    "\n",
    "# 拆分数据\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost 参数\n",
    "xgb_params = {\n",
    "    'n_estimators': 403,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.05, \n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'scale_pos_weight': 1627 / 1245,  # 类别不平衡处理\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "# xgb_params = {\n",
    "#     'n_estimators': 1500,             # 更多树，配合 early_stopping\n",
    "#     'max_depth': 12,                  # 树更深，学习更复杂非线性\n",
    "#     'learning_rate': 0.05,            # 更小步长，收敛更平缓\n",
    "#     'subsample': 0.6,                 # 行采样 60%，增强泛化\n",
    "#     'colsample_bytree': 0.6,          # 列采样 60%，防高维过拟合\n",
    "#     'min_child_weight': 3,            # 限制叶子节点最小权重\n",
    "#     'gamma': 0.5,                     # 分裂最小增益阈值\n",
    "#     'reg_alpha': 2.0,                 # L1 正则化更强\n",
    "#     'reg_lambda': 5.0,                # L2 正则化更强\n",
    "#     'scale_pos_weight': 1627/1245,    # 处理类别不平衡\n",
    "#     'objective': 'binary:logistic',\n",
    "#     # 'eval_metric': ['auc','logloss'],\n",
    "#     # 'use_label_encoder': False,\n",
    "#     'tree_method': 'hist',            # faster, handles high‑dim well\n",
    "#     'grow_policy': 'lossguide',       # 按损失导向生长，适合高维\n",
    "#     'n_jobs': -1,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# xgb_params = {\n",
    "#     'n_estimators': 1000,            # 增加树的数量，配合 early_stopping\n",
    "#     'max_depth': 10,                 # 略微加深，学习更复杂模式\n",
    "#     'learning_rate': 0.02,           # 更小步长，配合更多迭代\n",
    "#     'subsample': 0.7,                # 行采样比例，防过拟合\n",
    "#     'colsample_bytree': 0.7,         # 列采样比例，防过拟合\n",
    "#     'min_child_weight': 5,           # 叶子节点最小权重和\n",
    "#     'gamma': 0.3,                    # 分裂增益阈值\n",
    "#     'reg_alpha': 1.0,                # L1 正则化\n",
    "#     'reg_lambda': 3.0,               # L2 正则化\n",
    "#     'scale_pos_weight': 1627/1245,   # 处理类别不平衡\n",
    "#     'objective': 'binary:logistic',  \n",
    "#     'eval_metric': ['auc','logloss'],# 同时监控 AUC 和 logloss\n",
    "#     'use_label_encoder': False,\n",
    "#     'n_jobs': -1,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# 创建包含标准化的管道\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    xgb.XGBClassifier(**xgb_params)\n",
    ")\n",
    "\n",
    "# 5折交叉验证预测\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(model, X_new, y_new, cv=cv, method='predict')\n",
    "y_proba = cross_val_predict(model, X_new, y_new, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "# 模型拟合（用于提取特征重要性）\n",
    "model.fit(X_new, y_new)\n",
    "\n",
    "# 安全除法函数\n",
    "def safe_divide(a, b):\n",
    "    return a / b if b != 0 else 0\n",
    "\n",
    "# 混淆矩阵和指标\n",
    "cm = confusion_matrix(y_new, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "AAC = (TP + TN) / (TP + TN + FP + FN)\n",
    "Sn = safe_divide(TP, TP + FN)\n",
    "Sp = safe_divide(TN, TN + FP)\n",
    "MCC_num = (TP * TN - FP * FN)\n",
    "MCC_den = math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "MCC = safe_divide(MCC_num, MCC_den)\n",
    "AUC = roc_auc_score(y_new, y_proba)\n",
    "logloss = log_loss(y_new, y_proba)\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\n========== 交叉验证评估报告（XGBoost） ==========\")\n",
    "print(f\"准确率 (AAC): {AAC:.4f}\")\n",
    "print(f\"灵敏度 (Sn): {Sn:.4f}\")\n",
    "print(f\"特异度 (Sp): {Sp:.4f}\")\n",
    "print(f\"马修斯系数 (MCC): {MCC:.4f}\")\n",
    "print(f\"AUC分数: {AUC:.4f}\")\n",
    "print(f\"对数损失: {logloss:.4f}\")\n",
    "print(\"混淆矩阵:\")\n",
    "print(cm)\n",
    "\n",
    "# 特征重要性\n",
    "xgb_model = model.named_steps['xgbclassifier']\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "print(\"\\nTop 10重要特征:\")\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "feature_names = X_new.columns if hasattr(X_new, 'columns') else [f'Feature_{i}' for i in range(X_new.shape[1])]\n",
    "for i in sorted_idx[:10]:\n",
    "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 独立测试\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "\n",
    "# BACC_collection = []\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(2):\n",
    "    # dataset splitting\n",
    "    # X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "    \n",
    "    # Create and train Decision Tree classifier\n",
    "    # clf = RandomForestClassifier(max_depth=600, max_features=1, n_estimators=1000, n_jobs=-1)  # need to tune the hyperparameters\n",
    "    model.fit(X_new, y_new)\n",
    "    # clf = joblib.load('mode\\RF_ESM300/rf_ESM300_model_fold_5.joblib')\n",
    "    # Predict on independent test set\n",
    "    y_pred_score = model.predict_proba(X_new1)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)\n",
    "    y_true = y_new1\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    auc = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "  \n",
    "# Print results\n",
    "print(round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
