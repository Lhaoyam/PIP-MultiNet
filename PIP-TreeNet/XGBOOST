import math
import joblib
import numpy as np
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, roc_auc_score, log_loss



xgb_params = {
    'n_estimators': 403,
    'max_depth': 10,
    'learning_rate': 0.05, 
    'subsample': 1,
    'colsample_bytree': 1,
    'scale_pos_weight': 1627 / 1245, 
    'random_state': 42,
    'n_jobs': -1,
    'use_label_encoder': False,
    'eval_metric':'auc'
}

model = make_pipeline(
    StandardScaler(),
    xgb.XGBClassifier(**xgb_params)
)


cv = StratifiedKFold(n_splits=5)
y_pred = cross_val_predict(model, X_new, y_new, cv=cv, method='predict')
y_proba = cross_val_predict(model, X_new, y_new, cv=cv, method='predict_proba')[:, 1]


model.fit(X_new, y_new)


def safe_divide(a, b):
    return a / b if b != 0 else 0


cm = confusion_matrix(y_new, y_pred)
TN, FP, FN, TP = cm.ravel()

AAC = (TP + TN) / (TP + TN + FP + FN)
Sn = safe_divide(TP, TP + FN)
Sp = safe_divide(TN, TN + FP)
MCC_num = (TP * TN - FP * FN)
MCC_den = math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))
MCC = safe_divide(MCC_num, MCC_den)
AUC = roc_auc_score(y_new, y_proba)
logloss = log_loss(y_new, y_proba)


print(f"(AAC): {AAC:.4f}")
print(f"ÁÅµ (Sn): {Sn:.4f}")
print(f"(Sp): {Sp:.4f}")
print(f" (MCC): {MCC:.4f}")
print(f"{AUC:.4f}")
print(f"{logloss:.4f}")
print(cm)


xgb_model = model.named_steps['xgbclassifier']
importances = xgb_model.feature_importances_

sorted_idx = importances.argsort()[::-1]
feature_names = X_new.columns if hasattr(X_new, 'columns') else [f'Feature_{i}' for i in range(X_new.shape[1])]
for i in sorted_idx[:10]:
    print(f"{feature_names[i]}: {importances[i]:.4f}")

